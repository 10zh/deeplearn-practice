{
 "cells": [
  {
   "cell_type": "code",
   "id": "1ff4b946-3516-440f-a430-191bb97c7934",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:09.417033Z",
     "start_time": "2025-11-27T10:38:09.412470Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ],
   "outputs": [],
   "execution_count": 197
  },
  {
   "cell_type": "code",
   "id": "b25fff67-b24e-47e1-8d1b-36ada7275183",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:09.428045Z",
     "start_time": "2025-11-27T10:38:09.423987Z"
    }
   },
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,  # 词汇表大小\n",
    "    \"context_length\": 256,  # 上下文长度\n",
    "    \"emb_dim\": 768,  # 嵌入维度\n",
    "    \"n_heads\": 12,  # 注意力头数\n",
    "    \"n_layers\": 12,  #层数\n",
    "    \"drop_rate\": 0.1,  # Dropout率\n",
    "    \"qkv_bias\": False  # Query-Key-Value偏置\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 198
  },
  {
   "cell_type": "code",
   "id": "8eb8ab7d-4d6a-4045-9cc3-75503fcef935",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:09.442395Z",
     "start_time": "2025-11-27T10:38:09.433259Z"
    }
   },
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        #确保是可以被整除的\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "        #初始化头的维度、数量\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        #头的输出结合线性层\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        #进行dropout防止过拟合\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        #上三角掩码\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shape: (b, num_tokens, d_out)\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        #把输出的维度拆成头*头大小\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        #转制维度,听说是为了更好的计算注意力\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        # 计算缩放点积注意力\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "        # 将掩码缩减到当前 token 数量，并转换为布尔型\n",
    "        # 进而实现动态遮蔽,所以不用另开好几个数组\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        # 遮蔽矩阵\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        #归一化\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        #头的合并\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        #对上下文向量的形状进行调整，确保输出的形状\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)  # optional projection\n",
    "        return context_vec"
   ],
   "outputs": [],
   "execution_count": 199
  },
  {
   "cell_type": "code",
   "id": "6586ec24-1d79-4241-b035-4ab87db87a08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:09.448792Z",
     "start_time": "2025-11-27T10:38:09.446266Z"
    }
   },
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            #这一步把它变得平滑了很多\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ],
   "outputs": [],
   "execution_count": 200
  },
  {
   "cell_type": "code",
   "id": "b9ca919d-b85b-4da1-9d58-be622c029bd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:09.458359Z",
     "start_time": "2025-11-27T10:38:09.452878Z"
    }
   },
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    #运行一次就线性两次激活一次\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ],
   "outputs": [],
   "execution_count": 201
  },
  {
   "cell_type": "code",
   "id": "cc48b720-922d-49fe-881e-04f699b9a1cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:09.465794Z",
     "start_time": "2025-11-27T10:38:09.462628Z"
    }
   },
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ],
   "outputs": [],
   "execution_count": 202
  },
  {
   "cell_type": "code",
   "id": "f23ed206-6637-4ba4-a69d-9593e175ec8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:09.473498Z",
     "start_time": "2025-11-27T10:38:09.469816Z"
    }
   },
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],  # 输入特征维度\n",
    "            d_out=cfg[\"emb_dim\"],  # 输出特征维度\n",
    "            context_length=cfg[\"context_length\"],  # 上下文长度\n",
    "            num_heads=cfg[\"n_heads\"],  # 注意力头的数量\n",
    "            dropout=cfg[\"drop_rate\"],  # Dropout 比例\n",
    "            qkv_bias=cfg[\"qkv_bias\"]  # 查询、键和值的偏置\n",
    "        )  # 多头注意力模块，结合各种参数\n",
    "        self.ff = FeedForward(cfg)  # 前馈神经网络模块\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])  # 第一归一化层\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])  # 第二归一化层\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])  # 残差连接的 Dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 对注意力模块的快捷连接\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)  # 应用第一归一化层\n",
    "        x = self.att(x)  # 通过多头注意力模块，形状为 [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)  # 应用 Dropout\n",
    "        x = x + shortcut  # 将原始输入加回，实现残差连接\n",
    "\n",
    "        # 对前馈网络模块的残差连接\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)  # 应用第二归一化层\n",
    "        x = self.ff(x)  # 通过前馈神经网络模块\n",
    "        x = self.drop_shortcut(x)  # 应用 Dropout\n",
    "        x = x + shortcut  # 将原始输入加回，实现残差连接\n",
    "\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 203
  },
  {
   "cell_type": "code",
   "id": "7633f5b6-6303-4e9e-851b-69252f828f90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:09.481567Z",
     "start_time": "2025-11-27T10:38:09.477012Z"
    }
   },
   "source": [
    "class GPTModel(nn.Module):  #召唤GPT!\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        #新建字典、位置信息、还有dropout的比率设置\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        #解包操作\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            TransformerBlock(cfg),\n",
    "            TransformerBlock(cfg),\n",
    "            TransformerBlock(cfg)\n",
    "        )\n",
    "        #归一化\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        #输出头保证维度\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ],
   "outputs": [],
   "execution_count": 204
  },
  {
   "cell_type": "code",
   "id": "3eb8a39c-fc21-4f8b-aa49-ab65869d1d59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:09.489948Z",
     "start_time": "2025-11-27T10:38:09.486287Z"
    }
   },
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # 预测单词的模块\n",
    "    # idx 是当前上下文中的（batch, n_tokens）索引数组\n",
    "    for _ in range(max_new_tokens):\n",
    "        # 每次生成一个单词后，重新将其加入序列中\n",
    "        # 如果当前上下文长度超过模型支持的最大上下文长度，则截取\n",
    "        # 例如，如果LLM只支持5个token，而上下文长度为10\n",
    "        # 那么只使用最后5个token作为上下文\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        # 如果idx的长度超过模型支持的上下文长度size，只保留最后size个token\n",
    "        # 避免溢出\n",
    "        # 获取预测结果\n",
    "        with torch.no_grad():  # 在推理阶段，不需要计算梯度，因为没有反向传播\n",
    "            # 这样可以减少存储开销\n",
    "            logits = model(idx_cond)\n",
    "            # 模型输出结果\n",
    "        # 只关注最后一个时间步的输出\n",
    "        # (batch, n_tokens, vocab_size) 变为 (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "        # 关注最后一个时间步\n",
    "        # 使用softmax函数计算概率\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "        # 归一化\n",
    "        # 获取具有最高概率值的词汇索引\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "        # 获取概率最高的词汇索引\n",
    "        # 将采样的索引添加到序列中\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ],
   "outputs": [],
   "execution_count": 205
  },
  {
   "cell_type": "code",
   "id": "5595641d-46f3-4a95-906c-456fa02b140b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:10.473879Z",
     "start_time": "2025-11-27T10:38:09.495304Z"
    }
   },
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 206
  },
  {
   "cell_type": "code",
   "id": "9d013ebe-3c99-490e-a055-384fe85d0c0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:10.507170Z",
     "start_time": "2025-11-27T10:38:10.504070Z"
    }
   },
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "#给输入的字符进行编码并实现一个Batch维度的向量,符合模型的输入形式\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ],
   "outputs": [],
   "execution_count": 207
  },
  {
   "cell_type": "code",
   "id": "101177dc-3a09-438f-b971-3d24bc737d2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:10.718070Z",
     "start_time": "2025-11-27T10:38:10.512920Z"
    }
   },
   "source": [
    "#反向编码,去掉移除张量中的批次维度, 变成普通的链表\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "#举个例子\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    #初始上下文的Token ID张量，是上一步 text_to_token_ids 的输出\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "#输出最长单词度为10的句子\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you margins venconomicia inexperiencedeliwn Exit segregServer\n"
     ]
    }
   ],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:10.771361Z",
     "start_time": "2025-11-27T10:38:10.750253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "#引入数据集\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n",
    "#一系列经典的读取数据操作"
   ],
   "id": "f01a94024275729b",
   "outputs": [],
   "execution_count": 209
  },
  {
   "cell_type": "code",
   "id": "fd0c3bcd-e8c2-4968-b008-6469165bcb03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:10.796328Z",
     "start_time": "2025-11-27T10:38:10.778082Z"
    }
   },
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "execution_count": 210
  },
  {
   "cell_type": "code",
   "id": "04bb6ab0-7374-4905-963b-8380002c14df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:10.818182Z",
     "start_time": "2025-11-27T10:38:10.813751Z"
    }
   },
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    #让GPT初始化一个类型\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})  #id是文本内容编码过来的\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ],
   "outputs": [],
   "execution_count": 211
  },
  {
   "cell_type": "code",
   "id": "dda79fe2-cf29-4fc9-9c9d-8c1ef1ce15fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:10.825224Z",
     "start_time": "2025-11-27T10:38:10.821494Z"
    }
   },
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ],
   "outputs": [],
   "execution_count": 212
  },
  {
   "cell_type": "code",
   "id": "2c65dd69-aa90-4214-b5e9-d85f23f5f585",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:10.840616Z",
     "start_time": "2025-11-27T10:38:10.829286Z"
    }
   },
   "source": [
    "#从一个库导入之前的文章\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "#这边可以手动定义训练集跟测试剂的比例\n",
    "\n",
    "torch.manual_seed(123)\n",
    "#依旧保持可复现\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "#初始化输入训练模型,给出批处理的大小、给出最大文本容量防止溢出\n",
    "#给出不畅,丢弃最后一批不足的文本,打开随机防止拟合过度\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "#验证数据集仅仅修改了是否丢弃跟随抽取"
   ],
   "outputs": [],
   "execution_count": 213
  },
  {
   "cell_type": "code",
   "id": "bb0f3300-b953-4501-98fa-aa3ba0c15b28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:10.852582Z",
     "start_time": "2025-11-27T10:38:10.845706Z"
    }
   },
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "execution_count": 214
  },
  {
   "cell_type": "code",
   "id": "8b452c93-2a17-4ec8-9567-78ca101fd599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:10.864979Z",
     "start_time": "2025-11-27T10:38:10.861068Z"
    }
   },
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    #呼唤GPU\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    #用交叉熵函数对于logits进行计算并且拉伸到二维长度\n",
    "    return loss"
   ],
   "outputs": [],
   "execution_count": 215
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:10.873014Z",
     "start_time": "2025-11-27T10:38:10.868892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # 如果指定的批次数超过数据加载器中的总批次数，则将批次数减少到与数据加载器的总批次数匹配。\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "        #减少需要处理的数量,同时也是防止溢出\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "        #一点点加上去的损失\n",
    "    return total_loss / num_batches"
   ],
   "id": "e84e2b374f8fd574",
   "outputs": [],
   "execution_count": 216
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:12.788557Z",
     "start_time": "2025-11-27T10:38:10.877516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 对于 nn.Module 类，不需要赋值 model = model.to(device)\n",
    "model.to(device)\n",
    "\n",
    "# 固定随机种子，保证数据加载器打乱数据的结果可复现\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 禁用梯度跟踪以提高效率，因为此时尚未开始训练\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "# 推理阶段不计算梯度\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ],
   "id": "ed7062d1676d9e82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.975253211127388\n",
      "Validation loss: 10.943093299865723\n"
     ]
    }
   ],
   "execution_count": 217
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:38:12.822103Z",
     "start_time": "2025-11-27T10:38:12.815877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    #初始化训练模型而且给了空的队列\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):  #训练次数\n",
    "        model.train()  # Set model to training mode\n",
    "        #转移到训练模块\n",
    "        #从loader里面调出输入跟目标\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            #清空所有函数的梯度\n",
    "            optimizer.zero_grad()\n",
    "            #计算损失函数\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            #反向传播优化\n",
    "            loss.backward()\n",
    "            #更新权重\n",
    "            optimizer.step()\n",
    "            #加一下一共有多少\n",
    "            tokens_seen += input_batch.numel()\n",
    "            #看一下一共训练了多少步\n",
    "            global_step += 1\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                #按照一定的步数进行记录\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                #计算损失函数\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                #加到list中\n",
    "                print(f\"Ep {epoch + 1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "#评价模块\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    #检验模式\n",
    "    model.eval()\n",
    "    #我认为的双保险,防止梯度更新\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    #在评估结束后切换回训练模式，确保模型能继续用于训练。\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ],
   "id": "235d0bd75c083c17",
   "outputs": [],
   "execution_count": 218
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:40:03.121833Z",
     "start_time": "2025-11-27T10:38:12.826991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "#下面可以看一下计算了多久\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "#经典操作\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "#用Adam进行优化,其中学习rate为0.004,动量衰减是0.1\n",
    "num_epochs = 10\n",
    "#10论学习\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ],
   "id": "db5b5d70639c0bac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 10.518, Val loss 10.599\n",
      "Ep 1 (Step 000005): Train loss 8.335, Val loss 8.532\n",
      "Every effort moves you the the the the the the the the the the the the the the the the the the the the the the the the                          \n",
      "Ep 2 (Step 000010): Train loss 6.828, Val loss 7.243\n",
      "Ep 2 (Step 000015): Train loss 6.165, Val loss 6.687\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.905, Val loss 6.603\n",
      "Ep 3 (Step 000025): Train loss 5.660, Val loss 6.551\n",
      "Every effort moves you, and, and, and, and, and, and, the, and,, and,, and, and, the, and, the, and, and, and, the, and, the, and, and, and, the\n",
      "Ep 4 (Step 000030): Train loss 5.072, Val loss 6.444\n",
      "Ep 4 (Step 000035): Train loss 4.654, Val loss 6.237\n",
      "Every effort moves you?\"       \"I the fact. Gisburn. Gisburn's--and I had been. Gisburn's and I had to the fact--and I had the fact, and I had to the his\n",
      "Ep 5 (Step 000040): Train loss 4.136, Val loss 6.151\n",
      "Every effort moves you?\"  \"I the fact--and--I was his pictures. \"I--and, and I was, the donkey, in the picture--and, and I had the picture--and of his pictures--and, I was his\n",
      "Ep 6 (Step 000045): Train loss 3.920, Val loss 6.105\n",
      "Ep 6 (Step 000050): Train loss 3.443, Val loss 6.119\n",
      "Every effort moves you know he was, and I felt to the to the fact of the picture--I had been to me--and, and he had been. \"I his pictures--I had the picture--as of the, and I had been the his\n",
      "Ep 7 (Step 000055): Train loss 2.954, Val loss 6.055\n",
      "Ep 7 (Step 000060): Train loss 2.529, Val loss 6.085\n",
      "Every effort moves you know he was not to the picture--I had the fact with the last was not to see it's an awful. \"I had a degree he had the same quality, I had the honour of the donkey. \"There were, with his\n",
      "Ep 8 (Step 000065): Train loss 2.075, Val loss 6.085\n",
      "Ep 8 (Step 000070): Train loss 1.924, Val loss 6.118\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a little a little: make yourself comfortable--and here you know. Gisburn, and I looked at the donkey. Gisburn's his own \"There were, I had\n",
      "Ep 9 (Step 000075): Train loss 1.336, Val loss 6.174\n",
      "Ep 9 (Step 000080): Train loss 1.123, Val loss 6.232\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with equanimity.        He laughed again, and threw back his glory, he had the picture was his pictures. \"Oh, I was.\n",
      "Ep 10 (Step 000085): Train loss 0.926, Val loss 6.295\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "execution_count": 219
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:41:10.308107Z",
     "start_time": "2025-11-27T10:41:07.050184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "#一个经典的plot画图函数"
   ],
   "id": "1c53dd885d6e3bbd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 220
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
